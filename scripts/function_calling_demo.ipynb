{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download libraries if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (1.45.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.59.6-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/puneet.jain/miniforge3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Downloading openai-1.59.6-py3-none-any.whl (454 kB)\n",
      "\u001b[33mWARNING: Error parsing dependencies of textract: .* suffix can only be used with `==` or `!=` operators\n",
      "    extract-msg (<=0.29.*)\n",
      "                 ~~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.45.0\n",
      "    Uninstalling openai-1.45.0:\n",
      "      Successfully uninstalled openai-1.45.0\n",
      "Successfully installed openai-1.59.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#  %pip install monai==1.0.0 pytorch-ignite==0.4.11 autogen-agentchat~=0.2\n",
    "# %pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "from monai.bundle import run\n",
    "from monai.bundle.config_parser import ConfigParser\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get classification for an Mammogram Image using Monai Model Zoo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "\n",
    "def get_breast_density_classification(image_url : Annotated[str, \"the local path of the image\"]) -> dict:\n",
    "\n",
    "    d= {\"data\": {\n",
    "    \"_target_\": \"createList.CreateImagefromJson\",\n",
    "    \"J\": {\"image\" : image_url}}}\n",
    "    config_file = \"../configs/inference_new.json\"\n",
    "    parser = ConfigParser()    \n",
    "    parser.read_config(config_file)\n",
    "    run(config_file=config_file, workflow_type=\"inference\",**d)\n",
    "\n",
    "    data = parser.get_parsed_content(\"output_dir\")\n",
    "    df = pd.read_csv(f\"{data}/predictions.csv\",header=None)\n",
    "    return {\"Output\": chr(ord('@')+df[[1,2,3,4]].idxmax('columns')[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:17:39,074 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2025-01-16 14:17:39,075 - INFO - > config_file: '../configs/inference_new.json'\n",
      "2025-01-16 14:17:39,076 - INFO - > workflow_type: 'inference'\n",
      "2025-01-16 14:17:39,076 - INFO - > data: {'J': {'image': '/Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg'},\n",
      " '_target_': 'createList.CreateImagefromJson'}\n",
      "2025-01-16 14:17:39,078 - INFO - ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:17:39,481 - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n",
      "2025-01-16 14:17:39,620 - Restored all variables from ../models/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/handlers/checkpoint_loader.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.load_path, map_location=self.map_location)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:1512: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:17:46,523 - Key metric: None best value: -1 at epoch: -1\n",
      "2025-01-16 14:17:46,526 - Epoch[1] Complete. Time taken: 00:00:06.378\n",
      "2025-01-16 14:17:46,526 - Engine run complete. Time taken: 00:00:07.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/engines/evaluator.py:303: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(**engine.amp_kwargs):\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Output': 'D'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"/Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg\"\n",
    "get_breast_density_classification(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "dotenv_path = Path('.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:17:55,623 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ChatCompletion(id='chatcmpl-378a9554a9c948709abc31a0c8cc062d', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-f1ea767e22b841ea9f81a1e63d1345ed', function=Function(arguments='{\"team\": \"Arsenal\", \"gender\": \"male\"}', name='get_player_information'), type='function')]), stop_reason=None)], created=1737037073, model='default', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=27, prompt_tokens=1109, total_tokens=1136, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from mlflow.utils.databricks_utils import get_databricks_host_creds\n",
    "\n",
    "workspace_host = \"https://adb-984752964297111.11.azuredatabricks.net\"\n",
    "endpoint = f\"{workspace_host}/serving-endpoints\"\n",
    "token = os.environ['API_KEY']\n",
    "\n",
    "# Initialize the OpenAI client with the Databricks serving endpoint\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"intern-38b\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "    \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                      \"url\": \"https://www.arsenal.com/sites/default/files/styles/large_16x9/public/images/saka-celeb-bayern.png?h=3c8f2bed&auto=webp&itok=Twjeu8tug\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "    },\n",
    "    # {\"role\": \"user\", \n",
    "    # \"content\": [\n",
    "    #             {\n",
    "    #                 \"type\": \"text\",\n",
    "    #                 \"text\": \"What's the weather like in San Francisco?\"\n",
    "            \n",
    "    # }\n",
    "    # ]\n",
    "    # }\n",
    "  ],\n",
    "  tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_player_information\",\n",
    "        \"description\": \"This functions gets all details about a player shown in the image including where he is male/female and club affiliation\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team\": {\n",
    "                    \"type\":\n",
    "                    \"string\",\n",
    "                    \"description\":\n",
    "                    \"The sports club or team the player belongs to can be from any sport\"\n",
    "                },\n",
    "                \"gender\": {\n",
    "                    \"type\":\n",
    "                    \"string\",\n",
    "                    \"description\":\n",
    "                    \"The gender of the player can be either male or female or 'no player found'\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"team\", \"gender\"]\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"City and state, e.g., 'San Francisco, CA'\"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "],\n",
    "# tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_player_information\"}},\n",
    "  temperature=0.1,\n",
    "  max_tokens=200,\n",
    "\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "\n",
    "import autogen\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.capabilities.vision_capability import VisionCapability\n",
    "from autogen.agentchat.contrib.img_utils import get_pil_image, pil_to_data_uri\n",
    "from autogen.code_utils import content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"intern-38b\",\n",
    "            \"api_key\": str(os.environ[\"API_KEY\"]),\n",
    "            \"base_url\": endpoint,\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> dict:\n",
    "    if operator == \"+\":\n",
    "        return {\"response\" : int(a +b)}\n",
    "    elif operator == \"-\":\n",
    "        return {\"response\" : int(a - b)}\n",
    "    elif operator == \"*\":\n",
    "        return {\"response\" : int(a * b)}\n",
    "    elif operator == \"/\":\n",
    "        return {\"response\" : int(a / b)}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:18:17,712 - Tried to attach usage logger `pyspark.databricks.pandas.usage_logger`, but an exception was raised: JVM wasn't initialised. Did you call it on executor side?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> dict>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can help with simple calculations. \"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config={\"config_list\": llm_config['config_list']},\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(calculator)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"calculator\")(calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:2587: UserWarning: Function 'calculator' is being overridden.\n",
      "  warnings.warn(f\"Function '{tool_sig['function']['name']}' is being overridden.\", UserWarning)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:2506: UserWarning: Function 'calculator' is being overridden.\n",
      "  warnings.warn(f\"Function '{name}' is being overridden.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from autogen import register_function\n",
    "\n",
    "# Register the calculator function to the two agents.\n",
    "register_function(\n",
    "    calculator,\n",
    "    caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"calculator\",  # By default, the function name is used as the tool name.\n",
    "    description=\"A simple calculator\",  # A description of the tool.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What is (44232+654)*5 ?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:23,039 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:23] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:23,042 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (chatcmpl-tool-f8f507724d0941ff826f6db69e112b4d): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 44232, \"b\": 654, \"operator\": \"+\"}\n",
      "\u001b[32m********************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (chatcmpl-tool-f8f507724d0941ff826f6db69e112b4d) *****\u001b[0m\n",
      "{\"response\": 44886}\n",
      "\u001b[32m***************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:23,401 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:23] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:23,407 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:23,744 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:23] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:23,746 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:24,109 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:24] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:24,111 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:26,008 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:26] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:26,009 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "```json\n",
      "{\"name\": \"calculator\", \"arguments\": {\"a\": 44886, \"b\": 5, \"operator\": \"*\"}}\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:18:27,578 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:18:27] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:18:27,580 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "The result of (44232+654)*5 is 224,430. TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What is (44232+654)*5 ?\",silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/autogen/agentchat/conversable_agent.py:2587: UserWarning: Function 'get_breast_density_classification' is being overridden.\n",
      "  warnings.warn(f\"Function '{tool_sig['function']['name']}' is being overridden.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_breast_density_classification(image_url: typing.Annotated[str, 'the local path of the image']) -> dict>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant_p = MultimodalConversableAgent(\n",
    "    name=\"image-explainer\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config={\"config_list\": llm_config['config_list']},\n",
    "    system_message= \"you are an mammogram image analyser your job is to classify the breast density based on the mammogram provided use the tools in your you have specified and give explanation about the implications\"\n",
    "    \"Return 'TERMINATE' when the task is done.\"\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"get_breast_density_classification\", \n",
    "                           description=\"This a function which takes an input path which can be local path and gives classification of Density of the mammogram\")(get_breast_density_classification)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"get_breast_density_classification\")(get_breast_density_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import register_function\n",
    "\n",
    "# Register the calculator function to the two agents.\n",
    "register_function(\n",
    "    get_breast_density_classification,\n",
    "    caller=assistant_p,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"get_breast_density_classification\",  # By default, the function name is used as the tool name.\n",
    "    description=\"This a function which takes an input path which can be local path and gives classification of Density of the mammogram\",  # A description of the tool.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "\n",
    "def get_breast_density_classification(image_url : Annotated[str, \"the local path of the image\"]) -> dict:\n",
    "\n",
    "    # d= {\"data\": {\n",
    "    # \"_target_\": \"createList.CreateImagefromJson\",\n",
    "    # \"J\": {\"image\" : image_url}}}\n",
    "    # config_file = \"../configs/inference_new.json\"\n",
    "    # parser = ConfigParser()    \n",
    "    # parser.read_config(config_file)\n",
    "    # run(config_file=config_file, workflow_type=\"inference\",**d)\n",
    "\n",
    "    # data = parser.get_parsed_content(\"output_dir\")\n",
    "    # df = pd.read_csv(f\"{data}/predictions.csv\",header=None)\n",
    "    return {\"Outputs\" : \"D\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to image-explainer):\n",
      "\n",
      " local path of the mammogram  /Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg<image>\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:24:21,117 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:24:21] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:24:21,119 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mimage-explainer\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (chatcmpl-tool-e7eec9a0b8a440faab949970a77e6b5d): get_breast_density_classification *****\u001b[0m\n",
      "Arguments: \n",
      "{\"image_url\": \"/Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg\"}\n",
      "\u001b[32m*******************************************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_breast_density_classification...\u001b[0m\n",
      "2025-01-16 14:24:21,149 - INFO - --- input summary of monai.bundle.scripts.run ---\n",
      "2025-01-16 14:24:21,150 - INFO - > config_file: '../configs/inference_new.json'\n",
      "2025-01-16 14:24:21,150 - INFO - > workflow_type: 'inference'\n",
      "2025-01-16 14:24:21,151 - INFO - > data: {'J': {'image': '/Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg'},\n",
      " '_target_': 'createList.CreateImagefromJson'}\n",
      "2025-01-16 14:24:21,151 - INFO - ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s]\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:24:21,447 - Engine run resuming from iteration 0, epoch 0 until 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/handlers/checkpoint_loader.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.load_path, map_location=self.map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:24:21,490 - Restored all variables from ../models/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-16 14:24:27,719 - Key metric: None best value: -1 at epoch: -1\n",
      "2025-01-16 14:24:27,721 - Epoch[1] Complete. Time taken: 00:00:06.150\n",
      "2025-01-16 14:24:27,721 - Engine run complete. Time taken: 00:00:06.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/data/__init__.py:118: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/monai/engines/evaluator.py:303: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(**engine.amp_kwargs):\n",
      "/Users/puneet.jain/miniforge3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to image-explainer):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to image-explainer):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (chatcmpl-tool-e7eec9a0b8a440faab949970a77e6b5d) *****\u001b[0m\n",
      "[{'type': 'text', 'text': '{\"Output\": \"D\"}'}]\n",
      "\u001b[32m***************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "2025-01-16 14:24:47,409 - HTTP Request: POST https://adb-984752964297111.11.azuredatabricks.net/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[autogen.oai.client: 01-16 14:24:47] {351} WARNING - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "2025-01-16 14:24:47,412 - Model default is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mimage-explainer\u001b[0m (to User):\n",
      "\n",
      "The mammogram provided is classified as Density type \"D.\"\n",
      "\n",
      "Breast density is categorized into four types:\n",
      "- Type A: Almost entirely fatty\n",
      "- Type B: Scattered areas of fibroglandular density\n",
      "- Type C: Heterogeneously dense, which can make it hard to see some abnormalities\n",
      "- Type D: Extremely dense, making it the most difficult to interpret mammograms\n",
      "\n",
      "For type D density, it indicates that the breast tissue is extremely dense, which can make it challenging to detect abnormalities on a mammogram. This type of density may require additional or alternative screening methods, such as ultrasound, MRI, or 3D mammography, to ensure comprehensive evaluation.\n",
      "\n",
      "If you have any further questions or need additional assistance, feel free to ask.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': [{'type': 'text', 'text': ' local path of the mammogram  /Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg'}, {'type': 'image_url', 'image_url': {'url': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1890x2457 at 0x346C61D20>}}], 'role': 'assistant', 'name': 'User'}, {'tool_calls': [{'id': 'chatcmpl-tool-e7eec9a0b8a440faab949970a77e6b5d', 'function': {'arguments': '{\"image_url\": \"/Users/puneet.jain/Documents/Github/breast_density_classification/sample_data/D/sample_D3.jpg\"}', 'name': 'get_breast_density_classification'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}, {'content': '{\"Output\": \"D\"}', 'tool_responses': [{'tool_call_id': 'chatcmpl-tool-e7eec9a0b8a440faab949970a77e6b5d', 'role': 'tool', 'content': '{\"Output\": \"D\"}'}], 'role': 'tool', 'name': 'User'}, {'content': 'The mammogram provided is classified as Density type \"D.\"\\n\\nBreast density is categorized into four types:\\n- Type A: Almost entirely fatty\\n- Type B: Scattered areas of fibroglandular density\\n- Type C: Heterogeneously dense, which can make it hard to see some abnormalities\\n- Type D: Extremely dense, making it the most difficult to interpret mammograms\\n\\nFor type D density, it indicates that the breast tissue is extremely dense, which can make it challenging to detect abnormalities on a mammogram. This type of density may require additional or alternative screening methods, such as ultrasound, MRI, or 3D mammography, to ensure comprehensive evaluation.\\n\\nIf you have any further questions or need additional assistance, feel free to ask.\\n\\nTERMINATE', 'tool_calls': [], 'role': 'user', 'name': 'image-explainer'}], summary='The mammogram provided is classified as Density type \"D.\"\\n\\nBreast density is categorized into four types:\\n- Type A: Almost entirely fatty\\n- Type B: Scattered areas of fibroglandular density\\n- Type C: Heterogeneously dense, which can make it hard to see some abnormalities\\n- Type D: Extremely dense, making it the most difficult to interpret mammograms\\n\\nFor type D density, it indicates that the breast tissue is extremely dense, which can make it challenging to detect abnormalities on a mammogram. This type of density may require additional or alternative screening methods, such as ultrasound, MRI, or 3D mammography, to ensure comprehensive evaluation.\\n\\nIf you have any further questions or need additional assistance, feel free to ask.\\n\\n', cost={'usage_including_cached_inference': {'total_cost': 0, 'default': {'cost': 0, 'prompt_tokens': 19669, 'completion_tokens': 1664, 'total_tokens': 21333}}, 'usage_excluding_cached_inference': {'total_cost': 0, 'default': {'cost': 0, 'prompt_tokens': 19669, 'completion_tokens': 1664, 'total_tokens': 21333}}}, human_input=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask the question with an image\n",
    "# open method used to open different extension image file\n",
    "# Imports PIL module\n",
    "from PIL import Image\n",
    "im = Image.open(image_path)\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    assistant_p,\n",
    "    message = \n",
    "        {\n",
    "\n",
    "                \"content\": \n",
    "                    [   {\"type\": \"text\",\"text\" : f\" local path of the mammogram  {image_path}\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": im}},\n",
    "                        # {\"type\": \"text\",\"text\": \" classify the density of the breast?\"}\n",
    "                        ],\n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
